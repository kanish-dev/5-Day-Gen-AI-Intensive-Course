#**5-Day-Gen-AI-Intensive-Course**
## **DAY 1**
The first notebooks deals with 
> Prompting :The first notebook will show you how to get started with the gemini api and walk you through some of the example prompts and techniques that we can do easily.

## **DAY 2**
The next 3 notebooks deals with 
> Classifying-embeddings-with-keras : you'll learn to use the embeddings produced by the Gemini API to train a model that can classify newsgroup posts into the categories (the newsgroup itself) from the post contents.

>Document Q/A with RAG : you will use the Gemini API to create a vector database, retrieve answers to questions from the database and generate a final answer. You will use Chroma, an open-source vector database. With Chroma, you can store embeddings alongside metadata, embed documents and queries, and search your documents.

> The embeddings with simalarity score :  you will use the Gemini API's embedding endpoint to explore similarity scores.

## **DAY 3**
The next 2 notebooks deals with 
>Building-an-agent-with-langgraph :  you will use LangGraph to define a stateful graph-based application built on top of the Gemini API.You will build a simulated cafe ordering system, called BaristaBot. It will provide a looping chat interface to customers where they can order cafe beverages using natural language, and you will build nodes to represent the cafe's live menu and the "back room" ordering system.

>In the other notebook, you will use the Gemini API's automatic function calling to build a chat interface over a local database.

## **DAY 4**
The last 2 notebooks deals with 
> Fine-tuning-a-custom-model that will use the Gemini API to fine-tune a custom, task-specific model. Fine-tuning can be used for a variety of tasks from classic NLP problems like entity extraction or summarisation, to creative tasks like stylised generation. You will fine-tune a model to classify the category a piece of text 

> Google-search-grounding : you will use Google Search results with the Gemini API in a technique called grounding, where the model is connected to verifiable sources of information. Using search grounding is similar to using the RAG system you implemented earlier in the week, but the Gemini API automates a lot of it for you. The model generates Google Search queries and invokes the searches automatically, retrieving relevant data from Google's index of the web and providing links to search suggestions that support the query, so your users can verify the sources



